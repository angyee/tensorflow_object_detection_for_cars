# -*- coding: utf-8 -*-
"""ssd mobilenet v1 crowdai cars

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SU9kf1SVPLwZ2RvrNFA_134ilK3FvGSd
"""

#@title Installing dependencies { display-mode: "both" }
!apt-get install protobuf-compiler python-pil python-lxml python-tk
!pip install Cython
!pip install jupyter
!pip install matplotlib

#@title Clone the tensorflow repository
!git clone https://github.com/tensorflow/models.git

#@title train and eval folders for storing ckpt checkpoints after training
# %cd /content/models/research
# %mkdir train eval

#@title protobuf installation { display-mode: "both" }
!protoc object_detection/protos/*.proto --python_out=.
# %set_env PYTHONPATH=/content/models/research:/content/models/research/slim

#@title Installation test
!python object_detection/builders/model_builder_test.py

#@title Download and extract the dataset
!wget http://bit.ly/udacity-annoations-crowdai
!mv udacity-annoations-crowdai udacity-annoations-crowdai.tar.gz
!tar -xvf udacity-annoations-crowdai.tar.gz

#@title Resize the images
from os import listdir
filenames = [f for f in listdir("./object-detection-crowdai/")]
# %cd ./object-detection-crowdai/
import cv2
 
for f in filenames:
  if (f == "labels.csv"):
    continue
  image = cv2.imread(f)  
  dim = (960, 600)
  resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)
  cv2.imwrite(f, resized)
  print(f)

# %cd ..

#@title Download the model
!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz
!tar -xvf ssd_mobilenet_v1_coco_2017_11_17.tar.gz

#@title Import the model config file from google drive
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# 1. Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

#2. Get the file
downloaded = drive.CreateFile({'id':'sdfjgb9-q2sksbfkdsgksbjngfdjKVEFL2Pv'}) # replace with the id of file you want to access
downloaded.GetContentFile('ssd_mobilenet_v1_coco.config')

#@title Import the model config file from google drive
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# 1. Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

#2. Get the file
downloaded = drive.CreateFile({'id':'jksdgbksnnfkjgndfmKBHKHB45475hjbkbjb'}) # replace the id with id of file you want to access
downloaded.GetContentFile('labels_crowdai.csv')

#@title Import the model config file from google drive
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# 1. Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

#2. Get the file
downloaded = drive.CreateFile({'id':'rfbgKBKJBJH874eKKBBKB-IJB'}) # replace the id with id of file you want to access
downloaded.GetContentFile('car_label_map.pbtxt')

"""The following sections denotes the usage of Pandas library along with images to create TF records for training."""

annotation_path = "labels_crowdai.csv"
import pandas as pd
df = pd.read_csv(annotation_path, sep = ",")
print(df.columns)

df = df.drop(df.columns[ [-1] ], axis = 1)
df.head()
df = df[['Frame','xmin', 'ymin','xmax','ymax','Label']]
df.rename(columns={'Frame': 'frame', 'Label': 'label'}, inplace=True)
df.head()

import os
# cardfgg_1 = df[df.label == 'Car']
# cardfg_1 = cardfgg_1.groupby(['frame'], as_index = False)
cardfg_1 = df.groupby(['frame'], as_index = False)

cardfl_1 = cardfg_1.aggregate( lambda x : list(x) )

# Add relative path to files
cardfl_1.reset_index()
cardfl_1['frame'] = cardfl_1['frame'].apply(lambda x: os.path.join("./object-detection-crowdai", x))
cardfl_1.head()

import tensorflow as tf
from object_detection.utils import dataset_util
import hashlib
import io
import PIL.Image
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import cv2
#visualize dataset
f, axs = plt.subplots(3, 3, figsize = (15, 10))
for ii in range(3):
    for jj in range(3):
        inx = ii * 3 + jj + 100
        filename = cardfl_1.iloc[inx]['frame']
        xmin = cardfl_1.iloc[inx]['xmin']
        ymin = cardfl_1.iloc[inx]['ymin']
        xmax = cardfl_1.iloc[inx]['xmax']
        ymax = cardfl_1.iloc[inx]['ymax']
        img = mpimg.imread(filename)
        for xm,ym,xma,yma in zip(xmin, ymin,xmax,ymax):
            xm = int(xm)
            ym=int(ym)
            xma = int(xma)
            yma = int(yma)
            cv2.rectangle(img, (xm, ym), (xma,yma), color = (0,255,0), thickness = 2)
        if ii == 0 and jj == 0:
            print(img.shape)
        axs[ii, jj].imshow(img)
plt.tight_layout()

import tensorflow as tf
from object_detection.utils import dataset_util
import hashlib
import io
import PIL.Image

def create_tf_example(df_row):
  #Populate the following variables from your example.
  filename = df_row['frame']
  
  with tf.gfile.GFile(filename, 'rb') as fid:
    encoded_jpg = fid.read()
  
  encoded_image_data = io.BytesIO(encoded_jpg) # Encoded image bytes
  image = PIL.Image.open(encoded_image_data)
  if image.format != 'JPEG':
    raise ValueError('Image format not JPEG')
  key = hashlib.sha256(encoded_jpg).hexdigest()

  height = 600 # Image height
  width = 960 # Image width
  
  image_format = b'jpeg'

  xmins = [max(x / width, 0) for x in df_row['xmin'] ] # List of normalized left x coordinates in bounding box (1 per box)
  xmaxs = [min(x / width, 1) for x in df_row['xmax'] ] # List of normalized right x coordinates in bounding box
             # (1 per box)
  ymins = [max(y / height, 0) for y in df_row['ymin'] ] # List of normalized top y coordinates in bounding box (1 per box)
  ymaxs = [min(y / height, 1) for y in df_row['ymax'] ] # List of normalized bottom y coordinates in bounding box
             # (1 per box)
  classes_text = ["car".encode('utf8')] * len(xmins) # List of string class name of bounding box (1 per box)
  classes = [1] * len(xmins) # List of integer class id of bounding box (1 per box)
    
  fnamebytes = filename.encode()

  tf_example = tf.train.Example(features=tf.train.Features(feature={
      'image/height': dataset_util.int64_feature(height),
      'image/width': dataset_util.int64_feature(width),
      'image/filename': dataset_util.bytes_feature(fnamebytes),
      'image/source_id': dataset_util.bytes_feature(fnamebytes),
      'image/encoded': dataset_util.bytes_feature(encoded_jpg),
      'image/format': dataset_util.bytes_feature(image_format),
      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),
      'image/object/class/label': dataset_util.int64_list_feature(classes),
  }))
  return tf_example

import tensorflow as tf
from sklearn.model_selection import train_test_split

def write_records(output_path, df):
  writer = tf.python_io.TFRecordWriter(output_path)

  for _ , row in df.iterrows():
    tf_example = create_tf_example(row)
    writer.write(tf_example.SerializeToString())

  writer.close()

# #combine both datasets
# car_df_combined = pd.concat( [cardfl_1] )

#split dataset into training and test sets
train, test = train_test_split(cardfl_1, test_size = 0.2)

#write records

write_records('./train.record', train)
write_records('./test.record', test)

#@title Command to train
!python object_detection/train.py --logtostderr --pipeline_config_path=./ssd_mobilenet_v1_coco.config --train_dir=./train

#@title API to check RAM and GPU usage
!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi
!pip install gputil
!pip install psutil
!pip install humanize
import psutil
import humanize
import os
import GPUtil as GPU
GPUs = GPU.getGPUs()
# XXX: only one GPU on Colab and isnâ€™t guaranteed
gpu = GPUs[0]
def printm():
 process = psutil.Process(os.getpid())
 print("Gen RAM Free: " + humanize.naturalsize( psutil.virtual_memory().available ), " I Proc size: " + humanize.naturalsize( process.memory_info().rss))
 print("GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))
printm()

# %cd /content/

#@title Installation of Pycoco api
!git clone https://github.com/cocodataset/cocoapi.git
# %cd cocoapi/PythonAPI
!make
!cp -r pycocotools /content/models/research/

# %cd /content/models/research/

#@title Command for running evaluation

!python object_detection/eval.py --logtostderr --pipeline_config_path=./ssd_mobilenet_v1_cars.config --checkpoint_dir=./train --eval_dir=./eval

!ls ./train

"""Copy the latest trained checkpoints to a result folder"""

!mkdir results

!cp ./train/model.ckpt-5080.data-00000-of-00001 ./results

!cp ./train/model.ckpt-5080.index ./results

!cp ./train/model.ckpt-5080.meta ./results

!mkdir ssd_mobilnet_pb_20_06_1

"""Export the checkpoints to a frozen graph of format .pb. It would be needed during inference."""

!python object_detection/export_inference_graph.py  --input_type image_tensor --pipeline_config_path ./train/pipeline.config --trained_checkpoint_prefix ./results/model.ckpt-5080 --output_directory ./ssd_mobilnet_pb_20_06_1

"""Zip the pb graph and upload to google drive for later usage"""

!tar -czvf ssd_mobilnet_pb_20_06_1.tar.gz ./ssd_mobilnet_pb_20_06_1

#@title  { display-mode: "code" }
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# 1. Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

uploaded = drive.CreateFile({'title': 'ssd_mobilnet_pb_20_06_1.tar.gz'})
uploaded.SetContentFile('ssd_mobilnet_pb_20_06_1.tar.gz')
uploaded.Upload()
print('Uploaded file with ID {}'.format(uploaded.get('id')))

"""The following sections perform the inference"""

import numpy as np
import os
import six.moves.urllib as urllib
import sys
import tarfile
import tensorflow as tf
import zipfile

from collections import defaultdict
from io import StringIO
from matplotlib import pyplot as plt
from PIL import Image

# This is needed since the notebook is stored in the object_detection folder.
sys.path.append("..")
from object_detection.utils import ops as utils_ops

if tf.__version__ < '1.4.0':
  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')
  
# %matplotlib inline

from object_detection.utils import label_map_util

from object_detection.utils import visualization_utils as vis_util

PATH_TO_CKPT = './ssd_mobilnet_pb_20_06_1/frozen_inference_graph.pb'

PATH_TO_LABELS = './car_label_map.pbtxt'

NUM_CLASSES = 1

detection_graph = tf.Graph()
with detection_graph.as_default():
  od_graph_def = tf.GraphDef()
  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
    serialized_graph = fid.read()
    od_graph_def.ParseFromString(serialized_graph)
    tf.import_graph_def(od_graph_def, name='')

    
label_map = label_map_util.load_labelmap(PATH_TO_LABELS)
categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)
category_index = label_map_util.create_category_index(categories)

def load_image_into_numpy_array(image):
  (im_width, im_height) = image.size
  return np.array(image.getdata()).reshape(
      (im_height, im_width, 3)).astype(np.uint8)

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# 1. Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

#2. Get the file
downloaded = drive.CreateFile({'id':'kfdndgvkjfdnY86897kknHJBKKB'}) # replace the id with id of file you want to access
downloaded.GetContentFile('test_images.zip') 
!unzip test_images.zip

PATH_TO_TEST_IMAGES_DIR = './test_images'
TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 5) ]

# Size, in inches, of the output images.
IMAGE_SIZE = (12, 8)

def run_inference_for_single_image(image, graph):
  with graph.as_default():
    with tf.Session() as sess:
      # Get handles to input and output tensors
      ops = tf.get_default_graph().get_operations()
      all_tensor_names = {output.name for op in ops for output in op.outputs}
      tensor_dict = {}
      for key in [
          'num_detections', 'detection_boxes', 'detection_scores',
          'detection_classes', 'detection_masks'
      ]:
        tensor_name = key + ':0'
        if tensor_name in all_tensor_names:
          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(
              tensor_name)
      if 'detection_masks' in tensor_dict:
        # The following processing is only for single image
        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])
        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])
        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.
        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)
        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])
        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])
        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(
            detection_masks, detection_boxes, image.shape[0], image.shape[1])
        detection_masks_reframed = tf.cast(
            tf.greater(detection_masks_reframed, 0.5), tf.uint8)
        # Follow the convention by adding back the batch dimension
        tensor_dict['detection_masks'] = tf.expand_dims(
            detection_masks_reframed, 0)
      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')

      # Run inference
      output_dict = sess.run(tensor_dict,
                             feed_dict={image_tensor: np.expand_dims(image, 0)})

      # all outputs are float32 numpy arrays, so convert types as appropriate
      output_dict['num_detections'] = int(output_dict['num_detections'][0])
      output_dict['detection_classes'] = output_dict[
          'detection_classes'][0].astype(np.uint8)
      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]
      output_dict['detection_scores'] = output_dict['detection_scores'][0]
      if 'detection_masks' in output_dict:
        output_dict['detection_masks'] = output_dict['detection_masks'][0]
  return output_dict

for image_path in TEST_IMAGE_PATHS:
  image = Image.open(image_path)
  # the array based representation of the image will be used later in order to prepare the
  # result image with boxes and labels on it.
  image_np = load_image_into_numpy_array(image)
  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
  image_np_expanded = np.expand_dims(image_np, axis=0)
  # Actual detection.
  output_dict = run_inference_for_single_image(image_np, detection_graph)
  # Visualization of the results of a detection.
  vis_util.visualize_boxes_and_labels_on_image_array(
      image_np,
      output_dict['detection_boxes'],
      output_dict['detection_classes'],
      output_dict['detection_scores'],
      category_index,
      instance_masks=output_dict.get('detection_masks'),
      use_normalized_coordinates=True,
      line_thickness=8)
  plt.figure(figsize=IMAGE_SIZE)
  plt.imshow(image_np)

